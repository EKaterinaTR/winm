# План: Сервис графовой БД для визуальной новеллы (база знаний)

## Цель проекта

Сервис для заполнения и использования графовой БД связей между понятиями мира визуальной новеллы: локации, персонажи, сюжет. API для поиска, опционально — интеграция с LLM для ответов «по роли». Хранение в БД + по возможности в Git.

---

## 1. Архитектура системы

```
┌─────────────────┐     HTTP/REST      ┌─────────────────┐
│   Клиент/UI     │ ◄────────────────► │     Сервер      │
└─────────────────┘                    │  (API + метрики)│
                                       └────────┬────────┘
                                                │
                    ┌───────────────────────────┼───────────────────────────┐
                    │                           │                           │
                    ▼                           ▼                           ▼
            ┌───────────────┐           ┌───────────────┐           ┌───────────────┐
            │   RabbitMQ    │           │  Neo4j /      │           │  Prometheus   │
            │   (брокер)    │           │  графовая БД   │           │  (метрики)    │
            └───────┬───────┘           └───────────────┘           └───────────────┘
                    │
                    ▼
            ┌───────────────┐
            │  Consumer     │
            │  (обработка   │
            │   событий)    │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────┐
            │  Графовая БД  │
            └───────────────┘
```

- **Сервер**: REST API, публикация событий в брокер, сбор метрики (Prometheus).
- **Consumer**: подписка на очередь, обработка задач (создание/обновление сущностей в графе).
- **Графовая БД**: узлы (локации, персонажи, сцены, понятия) и рёбра (связи).

---

## 2. Выбор технологий

| Компонент        | Технология        | Обоснование |
|------------------|-------------------|-------------|
| Сервер           | **Node.js (NestJS)** или **Python (FastAPI)** | REST, очереди, тесты, метрики из коробки |
| Брокер сообщений | **RabbitMQ**      | Проще поднять в Docker, достаточная функциональность |
| Графовая БД      | **Neo4j**         | Стандарт для графов, Cypher, драйверы для Node/Python |
| Метрики          | **Prometheus**    | Экспорт метрик с сервера, scrape по HTTP |
| Визуализация     | **Grafana** (опц.)| Дашборды по метрикам |
| Хранение в Git   | **Экспорт в JSON/YAML** в репозиторий | Регулярный дамп сущностей в файлы, коммит через API или cron в контейнере |

Рекомендация по языку: **Python (FastAPI)** — быстрая разработка, хорошая поддержка Neo4j (neo4j), pika/celery для RabbitMQ, pytest + coverage 90%.

---

## 3. Структура проекта

```
winm/
├── docker-compose.yml      # Сервер, consumer, Neo4j, RabbitMQ, Prometheus, (Grafana)
├── .github/
│   └── workflows/
│       └── ci.yml          # CI: тесты + вывод покрытия
├── PLAN.md                 # Этот план
├── README.md
│
├── server/                 # REST API сервис
│   ├── Dockerfile
│   ├── requirements.txt
│   ├── app/
│   │   ├── main.py         # FastAPI app, метрики
│   │   ├── api/
│   │   │   ├── locations.py
│   │   │   ├── characters.py
│   │   │   ├── story.py
│   │   │   └── search.py   # Поиск по графу
│   │   ├── core/
│   │   │   ├── config.py
│   │   │   ├── graph.py    # Клиент Neo4j
│   │   │   └── broker.py   # Публикация в RabbitMQ
│   │   ├── models/
│   │   ├── services/
│   │   └── metrics.py     # Prometheus metrics
│   └── tests/
│       ├── conftest.py
│       ├── test_api_*.py
│       └── test_services_*.py
│
├── consumer/               # Обработчик очереди
│   ├── Dockerfile
│   ├── requirements.txt
│   ├── app/
│   │   ├── main.py         # Подключение к RabbitMQ, цикл consume
│   │   ├── handlers/       # Обработчики типов событий
│   │   ├── graph.py        # Запись в Neo4j
│   │   └── git_export.py  # (Опционально) экспорт в файлы для Git
│   └── tests/
│
├── shared/                 # Общие модели/константы (опционально, или дублировать в server/consumer)
│   └── events.py           # Типы событий, payload
│
├── prometheus/
│   └── prometheus.yml      # Конфиг сбора метрик с server
│
└── grafana/                # (Опционально) дашборды
    └── provisioning/
```

---

## 4. Сценарий работы (сервер → брокер → consumer)

1. **Запрос с сервера**: `POST /api/story/scenes` — создание сцены с привязкой к локации и персонажам.
2. **Сервер**:
   - Валидирует тело запроса.
   - Публикует событие в RabbitMQ (очередь `graph.tasks`) с типом `scene.create` и payload (scene_id, location_id, character_ids, description).
   - Возвращает клиенту `202 Accepted` и id задачи/сцены.
3. **Consumer**:
   - Получает сообщение из `graph.tasks`.
   - По типу события вызывает обработчик (например, `handle_scene_create`).
   - Обработчик формирует Cypher-запросы к Neo4j: создание узлов `Scene`, связей `TAKES_PLACE_IN` (локация), `FEATURES` (персонажи).
   - При необходимости пишет экспорт в папку (например, `exports/`) для последующего коммита в Git.
4. **Поиск**: `GET /api/search?q=локация+где+встретились+X+и+Y` — сервер сам ходит в Neo4j (или при желании может ставить задачу в очередь для тяжёлых запросов). Для «ответа по роли» можно добавить эндпоинт с вызовом LLM и контекстом из графа.

Таким образом, **запись в граф идёт через событие (сервер → RabbitMQ → consumer)**, а **чтение/поиск — напрямую с сервера в Neo4j**.

---

## 5. Модель графа (Neo4j)

- **Узлы**: `Location`, `Character`, `Scene`, `Concept` (общие понятия мира).
- **Связи** (примеры):
  - `Scene -[:TAKES_PLACE_IN]-> Location`
  - `Scene -[:FEATURES]-> Character`
  - `Character -[:APPEARS_IN]-> Scene`
  - `Character -[:KNOWS]-> Character`
  - `Concept -[:RELATES_TO]-> Concept` / связи с Location, Character по необходимости.

Атрибуты хранить в свойствах узлов (name, description, created_at и т.д.).

---

## 6. API (кратко)

- `POST/GET/PATCH/DELETE` для сущностей: локации, персонажи, сцены, понятия.
- `POST /api/...` на создание/обновление — сервер шлёт событие в брокер; после обработки consumer данные появляются в графе.
- `GET /api/search?q=...` — поиск по графу (Cypher по имени, тегам, связям).
- `GET /api/llm/answer` (опционально) — запрос с контекстом из графа + вызов LLM для ответа «от лица» персонажа или по миру.

---

## 7. Метрики (Prometheus)

- С сервера: `http_server_requests_total`, `http_server_request_duration_seconds`, количество запросов к Neo4j, количество опубликованных в RabbitMQ событий.
- Endpoint: `GET /metrics` (стандарт для Prometheus).
- В `docker-compose`: сервис `prometheus` с `scrape_config` на `server:8000`.

---

## 8. Хранение в Git

- **Вариант A**: Consumer после обновления графа пишет/обновляет файлы в смонтированном томе (например, `./data/git-export/`), а отдельный скрипт или cron внутри хоста делает `git add`, `commit`, `push` (репозиторий инициализирован в этой папке).
- **Вариант B**: Отдельный маленький сервис в Docker, который периодически дергает API экспорта (например, `GET /api/export/snapshot`), сохраняет JSON/YAML в файлы и коммитит в репозиторий (нужны credentials в секретах).
- Ограничение: внутри Docker без доступа к хостовому Git проще всего экспорт в **файлы в volume**; коммит/пуш с хоста — отдельным скриптом или cron на машине разработчика/сервера.

Итого: **реализуем экспорт в файлы (JSON/YAML) в заданную директорию**; инструкция в README — как привязать эту директорию к репо и настроить коммиты.

---

## 9. Docker

- **Сервисы**: `server`, `consumer`, `neo4j`, `rabbitmq`, `prometheus`, при желании `grafana`.
- Все порты и переменные окружения вынести в `docker-compose.yml` и `.env.example`.
- Запуск: `docker compose up -d` (или `docker compose up`) — поднимается вся система.
- Healthcheck для server и consumer (и при необходимости для Neo4j/RabbitMQ), чтобы зависимости стартовали по порядку.

---

## 10. Тесты и покрытие 90%

- **Сервер**: pytest, pytest-cov, pytest-asyncio. Тесты на API (TestClient), на сервисы (моки Neo4j и RabbitMQ), на метрики.
- **Consumer**: pytest, моки RabbitMQ и Neo4j; тесты обработчиков с подменой графа и брокера.
- **Покрытие**: `pytest --cov=app --cov-report=term-missing --cov-fail-under=90`.
- В CI (GitHub Actions): запуск тестов в контейнере или на установленном Python; артефакт или вывод в лог отчёта с покрытием (`coverage report` / `pytest --cov --cov-report=term`), чтобы в output CI было видно покрытие.

---

## 11. CI (GitHub Actions)

- Шаг: установка зависимостей, запуск линтера (ruff/black/flake8 — по выбору), запуск тестов с coverage.
- Условие: падение при покрытии ниже 90% (`--cov-fail-under=90`).
- В логе job явно выводить отчёт покрытия (term или xml + вывод файла).

---

## 12. Этапы реализации (после утверждения плана)

1. Инициализация репозитория: структура папок, `docker-compose` с Neo4j, RabbitMQ, Prometheus.
2. Сервер: FastAPI, конфиг, подключение к Neo4j и RabbitMQ, базовые эндпоинты CRUD (локации, персонажи, сцены) с публикацией событий.
3. Consumer: подключение к RabbitMQ, обработчики событий, запись в Neo4j по типам событий.
4. Поиск: эндпоинт `GET /api/search` с запросами к графу.
5. Метрики: Prometheus в сервере, конфиг Prometheus в docker-compose.
6. Экспорт в файлы для Git (в consumer или отдельный эндпоинт).
7. Опционально: эндпоинт с LLM для ответов по роли.
8. Тесты: достижение 90% покрытия по server и consumer.
9. CI: workflow с тестами и выводом покрытия.
10. README: как запускать, как использовать API, как настроить экспорт в Git.

---

Если план устраивает, можно переходить к реализации по этим этапам. Напиши, утверждаешь ли ты план и какой стек предпочитаешь (Python/FastAPI или Node/NestJS) — под него подстрою реализацию.
